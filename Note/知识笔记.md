## [hashMap](https://zhuanlan.zhihu.com/p/21673805):

内部类node节点组成的数组构成，实现了数组+链表/红黑树的结构

```
	final int hash;
    final K key;
    V value;
    Node<K,V> next;
```



![img](https://img2018.cnblogs.com/blog/1677914/201907/1677914-20190708102644222-1828130118.png)

1）通过hash(Object key)算法得到hash值；

2）判断table是否为null或者长度为0，如果是执行resize()进行扩容；

3）通过hash值以及table数组长度得到插入的数组索引i，判断数组table[i]是否为空或为null；
4）如果table[i] == null，直接新建节点添加，转向 8），如果table[i]不为空，转向 5）；
5）判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，这里的相同指的是hashCode以及equals，否则转向 6）；
6）判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转7）；
7）遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；
8）插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。

### hash算法：

```
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

**hashcode 与 hashcode的低16位做异或运算，混合了高位和低位得出的最终hash值，冲突的概率就小多了**

**线程不安全问题：**hashmap用数组+链表。数组是固定长度，链表太长就需要扩充数组长度进行rehash减少链表长度。如果两个线程同时触发扩容，在**移动节点时会导致一个链表中的2个节点相互引用，从而生成环链表**。jdk1.7及以前 **扩容时使用的头插法 并发时可能会形成环状链表造成死循环，1.8改为了尾插法，并且引入了头尾指针** 可以避免这种问题 只是依然**避免不了节点丢失**的问题。

1.7下形成环以后去取值可能会发生同步修改异常，大部分情况取到null

1.8以后避免不了节点的丢失，取不到最后一位

**HashMap的初始容量是2的n次幂**，扩容也是2倍的形式进行扩容，是因为容量是2的n次幂，

1、n-1的二进制会全为1，位运算时可以充分散列。避免不必要的哈希冲突可以使得**添加的元素均匀分布**在HashMap中的数组上，**减少hash碰撞**，避免形成链表的结构，使得查询效率降低！

2、resize过程中不需要像JDK1.7的实现那样重新计算hash，只需要看**看原来的hash值新增的那个bit是1还是0**就好了，是**0的话索引没变(e.hash & oldCap) == 0**，是**1的话索引变成“原索引+oldCap”**

3、采用二进制位操作&，相对于%能够提高运算效率。根据反汇编：

&操作用了:3mov+1and+1sub  %操作用了：2mov+1cdp+1idiv	汇编代码即使数量一样，每条指令的执行速度也不一样。

前者只需5个CPU周期，而后者至少需要26个CPU周期

**求余运算**。需要先将10进制转成2进制到内存中进行计算，然后再把结果转换成10进制

**位运算**是直接在内存中进行，不需要经过这些转换

**但是位运算只能用于除数是2的n次方的数的求余**

## LinkedHashMap：

内部类Entry继承自hashmap的node类，并且扩展了头尾节点，before和after，同时通过before，after实现了双向链表结构

```
static class Entry<K,V> extends HashMap.Node<K,V> {
    Entry<K,V> before, after;
    Entry(int hash, K key, V value, Node<K,V> next) {
        super(hash, key, value, next);
    }
}
```

在HashMap中没给具体实现，put，get方法中对**afterNodeAccess()**方法进行了重写具体实现。**目的是保证操作过的Node节点永远在最后，从而保证读取的顺序性**。根据结构方法中传入的accessOrder变量。如果为默认（false）就不会调整。还重写了其中的**afterNodeRemoval(Node e)**，该方法在HashMap中没有具体实现，通过**此方法在删除节点的时候调整了双链表的结构**。

**accessOrder为false时，你访问的顺序就是按照你第一次插入的顺序；而accessOrder为true时，你任何一次的操作，包括put、get操作，都会改变map中已有的存储顺序。其中使用的是LRU思路来实现**

## TreeMap:

```
static final class Entry<K,V> implements Map.Entry<K,V> {
    //key,val是存储的原始数据
    K key;
    V value;
    //定义了节点的左孩子
    Entry<K,V> left;
    //定义了节点的右孩子
    Entry<K,V> right;
    //通过该节点可以反过来往上找到自己的父亲
    Entry<K,V> parent;
    //默认情况下为黑色节点，可调整
    boolean color = BLACK;
```

TreeMap存储K-V键值对，通过红黑树（R-B tree）实现；

红黑树就是就是一颗非严格均衡的二叉树，均衡二叉树又是在**二叉搜索树的基础上增加了自动维持平衡的性质**，插入、搜索、删除的效率都比较高。

内部类Entry<K,V>中包含左右节点变量，还有父节点变量，以及一个color变量来标记颜色。默认为BLACK（True）,**插入元素使用二分法查找到位置后插入然后使用fixAfterInsertion(e)**;对其进行调整变色。

![img](https://img2018.cnblogs.com/blog/1677914/201907/1677914-20190721162700746-1542467354.png)

### map底层为什么要用红黑树实现

红黑树是二叉查找树，但在每个节点增加一个存储为表示节点的颜色，可以是红色或黑色（非红即黑），**通过对任意一条从根到叶子的路径上各个节点着色方式的限制，红黑树确保没有一条路径会比其他路径长两倍**。因此，它是一种弱平衡二叉树，相对于严格的AVL树来说，它的**旋转次数少**，所以对于查找、插入、删除较多的情况下，通常使用红黑树。

红黑树与AVL比较：

1. AVL是严格平衡的，频繁的插入和删除，会引起频繁的rebalance，导致效率降低；**红黑树是弱平衡的**，算是一种折中，插入最多旋转2次，删除最多旋转3次。

所以**红黑树在查找、插入删除的复杂度都是O(logn)，且性能稳定**，所以STL里面很多结构包括map底层都是使用的红黑树。

## HashSet

```
//默认构造器
public HashSet() {
    map = new HashMap<>();
}
```

HashSet，就对外接活儿，活儿接到了就直接扔给HashMap处理了。因为底层是通过HashMap实现的。

add方法时通过HashMap的put方法实现的，添加的元素是存放在HashMap的key位置上，而value取了默认常量PRESENT，是一个空对象

## LinkedHashSet

LinkedHashSet是HashSet的子类，构造器全部调用父类的，下面就是其父类HashSet的对此的构造方法

```
HashSet(int initialCapacity, float loadFactor, boolean dummy) {
    map = new LinkedHashMap<>(initialCapacity, loadFactor);
}
```

## TreeSet

TreeSet也完全依赖于TreeMap来实现

```
public TreeSet(Comparator<? super E> comparator) {
        this(new TreeMap<>(comparator));
    }
```

## ConcurrentHashMap

### JDK7版本:分段锁机制

每个对象中保存了一个Segment数组，即将整个Hash表划分为多个分段，一个Segment元素则与HashMap结构类似，其包含了一个HashEntry数组，用来存储Key/Value对。Segment继承了ReetrantLock，表示Segment是一个可重入锁，因此ConcurrentHashMap通过可重入锁对每个分段进行加锁。

### JDK8版本：加锁则采用CAS和synchronized实现

```
transient volatile Node<K,V>[] table;//默认没初始化的数组，用来保存元素
private transient volatile Node<K,V>[] nextTable;//转移的时候用的数组
/**
     * 用来控制表初始化和扩容的，默认值为0，当在初始化的时候指定了大小，这会将这个大小保存在sizeCtl中，大小为数组的0.75
     * 当为负的时候，说明表正在初始化或扩张，
     *     -1表示初始化
     *     -(1+n) n:表示活动的扩张线程
     */
    private transient volatile int sizeCtl;
```

使用的是HashMap一样的数据结构：数组+链表+红黑树。ConcurrentHashMap中包含一个table数组，其类型是一个Node数组，还包含一个重要属性**sizeCtl**，数组只有**在第一次添加元素的时候才会初始化**，设定了一个sizeCtl变量，用来**判断对象的一些状态**和**是否需要扩容其是一个控制标识符**。其为0时，表示hash表还未初始化，而为正数时这个数值表示初始化或下一次扩容的大小，相当于一个阈值；即如果hash表的实际大小>=sizeCtl，则进行扩容，默认情况下其是当前ConcurrentHashMap容量的0.75倍；而如果sizeCtl为-1，表示正在进行初始化操作；而为-N时，则表示有N-1个线程正在进行扩容。

#### 初始化：

- 使用一个循环实现table的初始化；在循环中，首先会判断sizeCtl的值，如果其小于0，则说明其正在进行初始化或扩容操作，则不执行任何操作，调用yield()方法使当前线程返回等待状态；而**如果sizeCtl大于等于0，则使用CAS操作(sc=sizeCtl)sc置为是-1**，表示进行初始化。初始化时，如果sizeCtl的值为0，则创建默认容量的table；否则创建大小为sizeCtl的table；然后重置sizeCtl的值为0.75n，即当前table容量的0.75倍，并返回创建的table，此时初始化hash表完成。

#### 扩容以及转化红黑树的机制：

**所以引起数组扩容的情况如下**：

　　1、只有在往map中添加元素的时候，在某一个节点的数目已经超过了8个，同时数组的长度又小于64的时候，才会触发数组的扩容。

　　2、当数组中元素达到了sizeCtl的数量的时候，则会调用transfer方法来进行扩容

- 默认初期长度为16，当往map中继续添加元素的时候，通过hash值跟数组长度取与来决定放在数组的哪个位置，如果出现在同一个位置的时候，优先以链表的形式存放，在**同一个位置的个数又达到了8个以上，再判断如果数组的长度还小于64的时候，则会扩容数组**。如果数组的长度大于等于64了的话，在会将该节点的链表转换成树。

转换为红黑树：**使用unSafe的CAS原子操作获取指定的Node节点，然后对该节点通过synchronized加锁**，由于只对一个Node节点加锁，因此该操作并不影响其他Node节点的操作，因此极大的提高了ConcurrentHashMap的并发效率。加锁之后，便是将这个Node节点所在的链表转换为TreeBin结构的红黑树。

查询时，首先通过tabAt()方法找到key对应的Node链表或红黑树，然后遍历该结构便可以获取key对应的value值。其中，tabAt()方法主要通过**Unsafe类的getObjectVolatile()**方法获取value值，通过**volatile读**获取value值，可以保证value值的可见性，从而保证其是当前最新的值。

- putVal()

```
     * 当添加一对键值对的时候，首先会去判断保存这些键值对的数组是不是初始化了，
     * 如果没有的话就初始化数组
     *  然后通过计算hash值来确定放在数组的哪个位置
     * 如果这个位置为空则直接添加，如果不为空的话，则取出这个节点来
     * 如果取出来的节点的hash值是MOVED(-1)的话，则表示当前正在对这个数组进行扩容，复制到新的数组，则当前线程调用helpTransfer()去帮助复制
     * 最后一种情况就是，如果这个节点，不为空，也不在扩容，则通过synchronized来加锁，进行添加操作
     *    然后判断当前取出的节点位置存放的是链表还是树
     *    如果是链表的话，则遍历整个链表，直到取出来的节点的key来个要放的key进行比较，如果key相等，并且key的hash值也相等的话，则说明是同一个key，则覆盖掉value，否则的话则添加到链表的末尾，取出来的元素的hash值大于0，当转换为树之后，hash值为-2。
     *    如果是树的话，则调用putTreeVal方法把这个元素添加到树中去
     *  最后在添加完成之后，会判断在该节点处共有多少个节点（注意是添加前的个数），如果达到8个以上了的话，
     *  则调用treeifyBin方法来尝试将处的链表转为树，或者扩容数组
```

#### 多个线程又是如何同步

同步主要是通过Synchronized和unsafe两种方式来完成的。

- 在获取sizeCtl、某个位置的Node的时候，使用的都是unsafe的CAS方法。

- 当需要在某个位置设置节点的时候，则会通过**Synchronized的同步机制**来锁定该位置的节点。tabAt()，casTAbAt();

- 在数组扩容的时候，则通过处理的步长和fwd节点（空节点）来达到并发安全的目的，通过设置hash值为MOVED（表示正在转移）

- 当把某个位置的节点复制到扩张后的table的时候，也通过Synchronized的同步机制来保证现程安全





## 什么是死锁？

### 一、定义

当线程互相持有对方所需要的资源时，会互相等待对方释放资源，如果线程都不主动释放所占有的资源，将产生死锁。

### 二、条件

1.互斥条件：进程对于所分配到的资源具有排它性，即一个资源只能被一个进程占用，直到被该进程释放  
2.请求和保持条件：一个进程因请求被占用资源而发生阻塞时，对已获得的资源保持不放。  
3.不剥夺条件：任何一个资源在没被该进程释放之前，任何其他进程都无法对他剥夺占用  
4.循环等待条件：当发生死锁时，所等待的进程必定会形成一个环路（类似于死循环），造成永久阻塞。

### 三、避免死锁

**1、最简单**的方法就是线程都是**以同样的顺序加锁和释放锁**，也就是破坏了第四个条件。

2、加锁时限，若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁。

3、死锁检测。



## 锁和CAS

https://blog.csdn.net/wen3011/article/details/78548521

### 锁

#### 悲观锁与乐观锁

独占锁是一种**悲观锁**，synchronized就是一种独占锁，会**导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁**。而另一个更加有效的锁就是乐观锁。所谓**乐观锁**就是，**每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止**。

#### 公平锁和非公平锁

https://www.bilibili.com/read/cv5333437

#### volatile

volatile变量是一和更轻量级的同步机制，因为在使用这些变量时**不会发生上下文切换和线程调度等操作**，但是volatile变量也存在一些局限：**不能用于构建原子的复合操作**，因此当一个变量依赖旧值时就不能使用volatile变量。

### CAS无锁算法

实现无锁的非阻塞算法有多种实现方法，其中 CAS（比较与交换，Compare and swap） 是一种有名的无锁算法。

CAS是一种 **乐观锁** 技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

- Unsafe类为我们提供了类似C++手动管理内存的能力。通过反射来获取Unsafe
- 使用提供的本地native方法compareAndSwapInt来完成值的比较和交换

#### CAS实现例子，以AtomicInteger为例

```
// AtomicInteger初始化过程
AtomicInteger atomicInteger = new AtomicInteger(666);

public AtomicInteger(int initialValue) {
        value = initialValue;
}
//Unsafe类为我们提供了类似C++手动管理内存的能力。
//通过反射来获取Unsafe
private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;

    static {
        try {
            valueOffset = unsafe.objectFieldOffset
                (AtomicInteger.class.getDeclaredField("value"));
        } catch (Exception ex) { throw new Error(ex); }
    }
private volatile int value;
```

```
// AtomicInteger执行getAndIncrement();
    public final int getAndIncrement() {
        return unsafe.getAndAddInt(this, valueOffset, 1); 
       //this:当前对象,valueOffset:value的内存地址
    }

    public final int getAndAddInt(Object var1, long var2, int var4) {
        int var5; //期望值
        do {
        //获取主内存中的value值(因为value为volatile，所以变化是实时可见的)
            var5 = this.getIntVolatile(var1, var2); 
		// compareAndSwapInt里会重新再取一次主内存的值，跟var5我们传入的期望值相比较，
		// 如果此时期望值跟我们主内存的值相等时(也就是值没有被修改过)才会退出循环，否则重新获取	
        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));
        return var5;
    }
```

### ABA问题：

第一个线程从内存的V位置取出A，这时第二个线程也从内存的V位置取出A，并将V位置的数据修改为B，接着又将V位置的数据修改为A，然后第一个线程操作成功。对于第一个线程来说，CAS操作是成功的，但是该过程中V位置的数据发生了变化，第一个线程感知不到，在某些应用场景下可能出现过程数据不一致的问题。

解决方法：

每次对共享变量进行修改操作时都会带上一个版本号，在预期的版本号和数据的版本号一致时就可以执行修改操作，并对版本号执行加1操作，否则执行失败。因为每次操作都会让版本号进行加。

使用`AtomicStampedReference<>`来封装共享变量，并且传入版本号。内部stamp来记录版本号，可以通过getStamp以后进行比较来控制版本。

## ThreadLocal

```
public T get() {
      //(1)获取当前线程
      Thread t = Thread.currentThread();
      //(2)获取当前线程的threadLocals变量
      ThreadLocalMap map = getMap(t);
 	  //(3)如果threadLocals变量不为null，就可以在map中查找到本地变量的值
      if (map != null) {
          ThreadLocalMap.Entry e = map.getEntry(this);
```

```
ThreadLocalMap getMap(Thread t) {
        return t.threadLocals;
    }
```

每个线程（Thread）内部有一个名为threadLocals的成员变量，该变量的类型为ThreadLocal.ThreadLocalMap类型（类似于一个HashMap），其中的key为当前定义的ThreadLocal变量的this引用，value为我们使用set方法设置的值。每个线程的本地变量存放在自己的本地内存变量threadLocals中。同一个ThreadLocal变量在父线程中被设置值后，**在子线程中是获取不到的。**

InheritableThreadLocal类提供子线程访问父线程的本地变量。

### 四大引用类型

| **类型**     | **回收时间**                            | **应用场景**                                     |
| ------------ | :-------------------------------------: | :----------------------------------------------------------: |
| 强引用   | 一直存活，除非GC Roots不可达            | 所有程序的场景，基本对象，自定义对象等                       |
| 软引用   | 内存不足时会被回收                      | 一般用在对内存非常敏感的资源上，用作缓存的场景比较多，例如：网页缓存、图片缓存 |
| 弱引用   | 只能存活到下一次GC前                    | 生命周期很短的对象，例如ThreadLocal中的Key。                 |
| 虚引用 | 随时会被回收， 创建了可能很快就会被回收 | 可能被JVM团队内部用来跟踪JVM的垃圾回收活动                   |

①强引用：Java中默认的引用类型，一个对象如果具有强引用那么只要这种引用还存在就不会被GC。

②软引用：简言之，如果一个对象具有弱引用，在JVM发生OOM之前（即内存充足够使用），是不会GC这个对象的；只有到JVM内存不足的时候才会GC掉这个对象。软引用和一个引用队列联合使用，如果软引用所引用的对象被回收之后，该引用就会加入到与之关联的引用队列中

③弱引用（这里讨论ThreadLocalMap中的Entry类的重点）：如果一个对象只具有弱引用，那么这个对象就会被垃圾回收器GC掉(被弱引用所引用的对象只能生存到下一次GC之前，当发生GC时候，无论当前内存是否足够，弱引用所引用的对象都会被回收掉)。弱引用也是和一个引用队列联合使用，如果弱引用的对象被垃圾回收期回收掉，JVM会将这个引用加入到与之关联的引用队列中。若引用的对象可以通过弱引用的get方法得到，当引用的对象呗回收掉之后，再调用get方法就会返回null

④虚引用：虚引用是所有引用中最弱的一种引用，其存在就是为了将关联虚引用的对象在被GC掉之后收到一个通知。（不能通过get方法获得其指向的对象）

### ThreadLocal使用不当的内存泄漏问题

ThreadLocalMap内部实际上是一个Entry数组，ThreadLocal的引用k被传递给WeakReference的构造函数，所以**ThreadLocalMap中的key为ThreadLocal的弱引用**。value就是通过set设置的值。如果当前线程一直存在且没有调用该ThreadLocal的remove方法，**弱引用在gc的时候就被回收，但是对应的value还是存在的这就可能造成内存泄漏。**在没有其他地方对ThreadLoca依赖，ThreadLocalMap中的ThreadLocal对象就会被回收掉，但是对应的不会被回收，这个时候**Map中就可能存在key为null但是value不为null的项**，这需要实际的时候使用完毕及时调用remove方法避免内存泄漏。

所以我们总结了使用ThreadLocal时会发生内存泄漏的前提条件：

- ①ThreadLocal引用被设置为null，且后面没有set，get,remove操作。
- ②线程一直运行，不停止。（线程池）
- ③触发了垃圾回收。（Minor GC或Full GC）
      我们看到ThreadLocal出现内存泄漏条件还是很苛刻的，所以我们只要破坏其中一个条件就可以避免内存泄漏，单但为了更好的避免这种情况的发生我们使用ThreadLocal时遵守以下两个小原则:
  - ①ThreadLocal申明为private static final。
             Private与final 尽可能不让他人修改变更引用，
             Static 表示为类属性，只有在程序结束才会被回收。
  - ②ThreadLocal使用后务必调用remove方法。
            最简单有效的方法是使用后将其移除。



## 不可重入锁

### synchronized wait notify 方式实现

```
public class NonReentrantLockBywait {
    //是否被锁
    private volatile boolean locked = false;
    //加锁
    public synchronized void lock(){
        while (locked){
            try {
                wait();
            }catch (InterruptedException e){
                e.printStackTrace();
            }
        }
        //加锁成功 locked设置为true
        locked = true;
    }
    //释放锁
    public synchronized void unLock(){
        locked = false;
        notify();
    }
}
```

### 通过CAS + 自旋方式实现

```
class NonReentrantLockByCAS {

    private AtomicReference<Thread> lockedThread = new AtomicReference<Thread>();

    public void lock() {
        Thread t = Thread.currentThread();
        //当 lockedThread 持有引用变量为 null 时，设置 lockedThread 持有引用为 当前线程变量
        while (!lockedThread.compareAndSet(null, t)) {
            //自旋，空循环，等到锁被释放
        }
    }
    public void unlock() {
        //如果是本线程锁定的，可以成功释放锁
        lockedThread.compareAndSet(Thread.currentThread(), null);
    }
}
```




## synchronized和 Lock 的区别

1）**Lock是一个接口，而synchronized是Java中的关键字**，synchronized是内置的语言实现；

2）**synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生**；而**Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁**；

3）**Lock可以让等待锁的线程响应中断**，而**synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断**；

4）**通过Lock可以知道有没有成功获取锁（tryLock()方法：如果获取锁成功，则返回true）**，而**synchronized却无法办到**。

5）**Lock可以提高多个线程进行读操作的效率**。

**ReentrantLock 比 synchronized 增加了一些高级功能，主要有3点：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）**

- ReentrantLock提供了一种能够中断等待锁的线程的机制，也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。通过lock.lockInterruptibly()来实现这个机制。ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。（公平锁就是先等待的线程先获得锁）
- synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制。ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。用ReentrantLock类结合Condition实例可以实现“选择性通知” 。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程

## 线程池

### 使用Executor框架来创建线程池

- **FixedThreadPool：可重用固定线程数的线程池**。（适用于负载比较重的服务器）
  - **FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列**
  - 该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。

- **SingleThreadExecutor：只会创建一个线程执行任务**。（适用于需要保证顺序执行各个任务；并且在任意时间点，没有多线程活动的场景。）
  - **SingleThreadExecutorl也使用无界队列LinkedBlockingQueue作为工作队列**
  - 若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
- **CachedThreadPool：是一个会根据需要调整线程数量的线程池。**（大小无界，适用于执行很多的短期异步任务的小程序，或负载较轻的服务器）
  - **CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列，但CachedThreadPool的maximumPool是无界的。**
  - 线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。

- **Executor执行Callable任务：**

　　当将一个Callable的对象传递给ExecutorService的**submit方法**，则该call方法自动在一个线程上执行，并且**会返回执行结果Future对象**。同样，将Runnable的对象传递给ExecutorService的submit方法，则该run方法自动在一个线程上执行，并且会返回执行结果Future对象，但是在该Future对象上调用get方法，将返回null。

#### 执行execute()方法和submit()方法的区别是什么呢？

1) **execute() 方法用于提交不需要返回值的任务**，所以无法判断任务是否被线程池执行成功与否；

2) **submit() 方法用于提交需要返回值的任务**。线程池会返回一个**Future**类型的对象，通过这个Future对象可以判断任务是否执行成功，并且可以**通过future的get()方法来获取返回值**，get()方法会阻塞当前线程直到任务完成，而使用 `get（long timeout，TimeUnit unit）`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

## 阻塞队列

阻塞队列不可用时，这两个附加操作提供了4种处理方式

| 方法\处理方式 | 抛出异常  | 返回特殊值 | 一直阻塞 | 超时退出           |
| :------------ | :-------- | :--------- | :------- | :----------------- |
| 插入方法      | add(e)    | offer(e)   | put(e)   | offer(e,time,unit) |
| 移除方法      | remove()  | poll()     | take()   | poll(time,unit)    |
| 检查方法      | element() | peek()     | 不可用   | 不可用             |

### 1、ArrayBlockingQueue

基于数组的阻塞队列实现，内部维护了一个定长数组，**内部还保存着两个整形变量**，分别标识着**队列的头部和尾部在数组中的位置**。生产者放入数据和消费者获取数据，都是**共用同一个锁对象**。数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，只会给代码带来额外的复杂性。而且在插入或删除元素时不会产生或销毁任何额外的对象实例。创建ArrayBlockingQueue时，我们还可以控制对象的内部锁是否采用公平锁，**默认采用非公平锁**。

### 2、LinkedBlockingQueue

基于链表的阻塞队列，内部维持着一个数据缓冲队列（该队列由链表构成），只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其**对于生产者端和消费者端分别采用了独立的锁来控制数据同步**，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。

如果没有指定其容量大小，LinkedBlockingQueue会**默认一个类似无限大小的容量**（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。

### 3、DelayQueue

DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue是一个没有大小限制的队列，因此往队列中**插入数据的操作（生产者）永远不会被阻塞**，而**只有获取数据的操作（消费者）才会被阻塞**。

　　使用场景：

　　DelayQueue使用场景较少，但都相当巧妙，常见的例子比如使用一个DelayQueue来**管理一个超时未响应的连接队列**。

### 4、PriorityBlockingQueue

基于优先级的阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），但需要注意的是PriorityBlockingQueue并**不会阻塞数据生产者**，而只会在没有可消费的数据时，**阻塞数据的消费者**。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现PriorityBlockingQueue时，**内部控制线程同步的锁采用的是公平锁**。

### 5、SynchronousQueue

SynchronousQueue，是一种无缓冲的等待队列，可以认为SynchronousQueue是一个**缓存值为1的阻塞队列**。有两种不同的方式，它们之间有着不太一样的行为。公平模式和非公平模式的区别:

　　如果采用**公平模式**：SynchronousQueue**会采用公平锁**，**并配合一个FIFO队列**来阻塞多余的生产者和消费者，从而体系整体的公平策略；

　　但如果是**非公平模式**（SynchronousQueue**默认**）：SynchronousQueue**采用非公平锁**，**同时配合一个LIFO队列**来管理多余的生产者和消费者，而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理。

## 非阻塞队列：

### ConcurrentLinkedQueue

 ConcurrentLinkedQueue是一个基于**单向链表的无界线程安全队列**，它采用**先进先出的规则对节点进行排序**，当我们添加一个元素的时候，它会添加到队列的尾部；当我们获取一个元素时，它会返回队列头部的元素。**入队和出队操作均利用CAS（compare and set）更新**，这样允许多个线程并发执行，并且不会因为加锁而阻塞线程，使得并发性能更好。



## [MySQL数据库的锁机制](https://zhuanlan.zhihu.com/p/85889976)

- InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁。行级锁的缺点是：由于需要请求大量的锁资源，所以速度慢，内存消耗大。
- 只有**通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁**
- **update,delete,insert都会自动给涉及到的数据加上排他锁**。select语句默认不会加任何锁类型，如果加排他锁可以使用select …for update语句，加共享锁可以使用select … lock in share mode语句。

### 表级锁

- InnoDB 表存在**两种表级锁**，一种是`LOCK TABLES`语句手动指定的锁，另一种是由 InnoDB **自动添加的意向锁**。

使用`lock tables ... write`语句为表 t **加上表级排他锁**；因为意向排他锁和表级排他锁冲突，所以该语句也会一直等待 T1 释放锁。`unlock tables`语句用于**释放该表上的排他锁**。

**意向锁属于表级锁**，由 InnoDB 自动添加，不需要用户干预。**意向锁也分为共享和排他两种方式**：

- 意向锁是为了使得行锁和表锁能够共存，从而实现多粒度的锁机制

意向共享锁（IS）：事务在给数据行加行级共享锁之前，必须先取得该表的 IS 锁。
意向排他锁（IX）：**事务在给数据行加行级排他锁之前，必须先取得该表的 IX 锁**。
此时，事务 A 必须先申请该表的意向共享锁，成功后再申请数据行的行锁。事务 B 申请表锁时，数据库查看该表是否已经被其他事务加上了表级锁；如果发现该表上存在意向共享锁，说明表中某些数据行上存在共享锁，事务 B 申请的写锁会被阻塞。

### 行级锁与死锁

- MyISAM中是不会产生死锁的，因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待。而在InnoDB中，锁是逐步获得的，就造成了死锁的可能。

  在MySQL中，行级锁并不是直接锁记录，而是锁索引。如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking。

  当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引。另一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。
  
  #### [InnoDB支持的行级锁](https://blog.csdn.net/horses/article/details/103324323?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase):

Record Lock(记录锁): **对索引项加锁，锁定符合条件的行**。其他事务不能修改和删除加锁项；

- **记录锁永远都是锁定索引记录**，锁定非聚集索引会先锁定聚集索引。如果表中没有定义索引，InnoDB 默认为表创建一个隐藏的聚簇索引，并且使用该索引锁定记录。（是唯一索引时）

Gap Lock（间隙锁）: 对索引项的“间隙”加锁，**锁定的是索引记录之间的间隙、第一个索引之前的间隙或者最后一个索引之后的间隙，不包含索引项本身。**其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。
Next-key Lock： 锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合。可解决幻读问题。

（唯一索引操作范围值、通过普通索引操作单个值、通过普通索引操作范围值、无索引操作单个值或范围值）

- 如果**索引有唯一属性**，则 InnnoDB 会自动将 next-key 锁降级为记录锁。

### 共享锁与排它锁

#### 共享锁（Share Lock）

- **共享锁又称读锁**，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。

如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排他锁。获准共享锁的事务只能读数据，不能修改数据。用法： `SELECT ... LOCK IN SHARE MODE;`

在查询语句后面增加LOCK IN SHARE MODE，Mysql会对查询结果中的每行都加共享锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。其他线程也可以读取使用了共享锁的表，而且这些线程读取的是同一个版本的数据。

#### 排它锁（eXclusive Lock）

- **排他锁又称写锁**，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任何类型的锁。获准排他锁的事务既能读数据，又能修改数据。用法： `SELECT ... FOR UPDATE`;

在查询语句后面增加FOR UPDATE，Mysql会对查询结果中的每行都加排他锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请排他锁，否则会被阻塞。

#### 乐观锁（Optimistic Lock）

- 假设认为数据不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。

乐观锁并不会使用数据库提供的锁机制。一般的实现乐观锁的方式就是验证数据和记录数据版本。

数据版本,为数据增加的一个版本标识。在一个事务中，读取数据时，将版本标识的值一同读出，数据每更新一次，同时对版本标识进行更新。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对，如果数据库表当前版本号与第一次取出来的版本标识值相等，则予以更新，否则认为是过期数据。

实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳。

##### 使用版本号实现乐观锁

- 使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号。

```text
1.查询出商品信息
select (status,version) from t_goods where id=#{id}
2.根据商品信息生成订单
3.修改商品status为2
update t_goods
set status=2,version=version+1
where id=#{id} and version=#{version};
```

##### 优点

- 乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。

#### 悲观锁（Pessimistic Lock）

- 在整个数据处理过程中，将数据处于锁定状态。悲观锁，依靠数据库提供的锁机制 （也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）

##### 悲观锁的流程

- 在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。
- 如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。具体响应方式由开发者根据实际需要决定。
- 如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。
- 其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。

##### MySQL InnoDB中使用悲观锁

- 要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。set autocommit=0;

```text
//0.开始事务
begin;
//1.查询出商品信息
select status from t_goods where id=1 for update;
//2.根据商品信息生成订单
insert into t_orders (id,goods_id) values (null,1);
//3.修改商品status为2
update t_goods set status=2;
//4.提交事务
commit;
```

上面的查询语句中，我们使用了`select…for update`的方式，这样就通过开启排他锁的方式实现了悲观锁。此时在t_goods表中，id为1的 那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。



### [MySQL-MVCC多版本并发控制](https://segmentfault.com/a/1190000012650596)

InnoDB存储引擎在数据库每行数据的后面添加了三个字段

- `事务ID`(`DB_TRX_ID`)字段: 用来标识最近一次对本行记录做修改(insert|update)的事务的标识符, 即最后一次修改(insert|update)本行记录的事务id。
- `回滚指针`(`DB_ROLL_PTR`)字段: 指向写入回滚段(rollback segment)的 `undo log` record (撤销日志记录)。
- `DB_ROW_ID`字段：如果没有自己的主键或者合适的唯一索引，InnoDB会帮我们自动生成聚集索引, 但聚簇索引会使用DB_ROW_ID的值来作为主键; 如果我们有自己的主键或者合适的唯一索引, 那么聚簇索引中也就不会包含 DB_ROW_ID 了 。

#### InnoDB实现MVCC的方式是:

- 事务以排他锁的形式修改原始数据
- 把修改前的数据存放于undo log，通过回滚指针与主数据关联
- 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback）

## Innodb在RR级别如何避免幻读

### 幻读定义

事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。 同时，第二个事务也修改这个表中的数据，这种修改是向表中**插入一行新数据**。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象 发生了幻觉一样。

### mysql如何实现避免幻读

1.在快照读读情况下，mysql通过mvcc来避免幻读。(简单的select操作，属于快照读，不加锁。)

- InnoDB为每行记录添加了一个事务ID，每当修改数据时，将当事务ID写入。
  在读取事务开始时，系统会给事务一个当前版本号(事务ID)，事务会读取版本号<=当前版本号的数据，这时就算另一个事务插入一个数据，并立马提交，新插入这条数据的版本号会比读取事务的版本号高，因此读取事务读的数据还是不会变。

2.在当前读读情况下，mysql通过next-key来避免幻。(特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。)



## Minor GC、Major GC、Full GC

### Full GC的触发条件：

- 程序执行了System.gc() //建议jvm执行fullgc，并不一定会执行

- 执行了jmap -histo:live pid命令 //这个会立即触发fullgc

- 在执行minor gc的时候进行的一系列检查

Minor GC：**发生在年轻代的GC**。
**Minor GC的触发条件**为：当产生一个新对象，新对象优先在Eden区分配。如果Eden区放不下这个对象，虚拟机会发生一次Minor GC，清除掉无用对象，同时将存活对象移动到Survivor的其中一个区(fromspace区或者tospace区)。虚拟机会给每个对象定义一个对象年龄(Age)计数器，对象在Survivor区中每“熬过”一次GC，年龄就会+1。待到年龄到达一定岁数(默认是15岁)，虚拟机就会将对象移动到年老代。如果Survivor区放不下从Eden区过来的对象时，此时会使用**分配担保机制**将对象直接移动到年老代。

**Major GC的触发条件**：当年老代空间不够用的时候，虚拟机会使用“标记—清除”或者“标记—整理”算法清理出连续的内存空间，分配对象使用。
大家注意：Major GC和Full GC是不一样的，前者只清理老年代，后者会清理年轻代+老年代

**minorGC检查机制：**

- 执行Minor GC的时候，JVM会检查老年代中**最大连续可用空间是否大于了当前新生代所有对象的总大小**。
  如果大于，则直接执行Minor GC（这个时候执行是没有风险的）。
  如果小于了，JVM会检查是否开启了空间分配担保机制，如果**没有开启则直接改为执行Full GC**。
  如果开启了，则JVM会检查老年代中最大连续可用空间是否大于了历次晋升到老年代中的平均大小，如果小于则执行改为执行Full GC。
  如果大于则会执行Minor GC，如果Minor GC执行失败则会执行Full GC

1、频繁FullGC排查原因，我们在线上开启了 -XX:+HeapDumpBeforeFullGC。JVM在执行dump操作的时候是会发生stop the word事件的，也就是说此时所有的用户线程都会暂停运行。

2、dump下来的文件大约1.8g，用jvisualvm查看，发现用char[]类型的数据占用了41%内存，同时另外一个com.alibaba.druid.stat.JdbcSqlStat类型的数据占用了35%的内存，也就是说整个堆中几乎全是这两类数据。

3、查看char[]的引用找到了JdbcSqlStat类，因为我们使用的数据源是阿里巴巴的druid，这个druid提供了一个sql语句监控功能，同时我们也开启了这个功能。只需要在配置文件中把这个功能关掉应该就能消除这个问题，事实也的确如此，关掉这个功能后到目前为止线上没再触发FullGC

## final,finally,finalize区别

**final**

final修饰类，表示该类不可以被继承
final修饰变量，表示该变量不可以被修改，只允许赋值一次
final修饰方法，表示该方法不可以被重写

**finally**

finally是java**保证代码一定要被执行的一种机制**。
比如try-finally或try-catch-finally，用来关闭JDBC连接资源，**用来解锁**等等

**finalize**

finalize()方法是Object类中提供的一个方法，在GC准备释放对象所占用的内存空间之前，它将首先调用finalize()方法，目的是保证对象在**被垃圾收集前完成特定资源的回收**。由于GC的自动回收机制，因而并不能保证finalize方法会被及时地执行（垃圾对象的回收时机具有不确定性），也不能保证它们会被执行(程序由始至终都未触发垃圾回收)。

在可达性分析算法中不可达的对象，也并非马上就会被清理掉。

要真正宣告一个对象死亡，至少要经历**两次标记过程**：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，看 对象是否有必要执行finalize（）方法。当对象没有覆盖finalize（）方法，或者finalize（）方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。

如果这个对象被判定为有必要执行finalize（）方法，那么这个**对象将会放置在一个叫做F-Queue的队列**之中，并在稍后由一个由虚拟机自动建立的、**低优先级的Finalizer线程去执行它**。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize（）方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。finalize（）方法是对象逃脱死亡命运的最后一次机会，稍后**GC将对F-Queue中的对象进行第二次小规模的标记**，如果对象要在finalize（）中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的被回收了。






## 缓存雪崩

- 事后，redis持久化机制，RDB(快照)+AOF(追加文件)

1、redis高可用，搭建的集群，主从同步，读写分离。

2、错开缓存失效时间

3、本地缓存+Hystrix限流

4、数据预热：在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。

## 缓存击穿

1、接口层加入基础校验，简单参数校验不通过就返回

2、把找不到的key值也缓存到redis，并且设置较短的过期时间

3、nginx层设置对单个IP超出阈值都拉黑

4、布隆过滤器：利用简单高效的算法判断key是否存在于数据库

**将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。**

## 秒杀优化

https://blog.csdn.net/a724888/article/details/81038138

https://www.bilibili.com/read/cv5047955

### 架构设计思想

1、限流：控制大部分流量，只允许少部分流量进入服务器后端。

2、削峰：把瞬间的高流量变成平稳流量，利用缓存和消息中间件等技术。

3、异步处理：采用异步处理模块提高并发量，将同步的业务，设计成异步处理的任务，也是削峰的一种方式。

4、把部分数据和业务逻辑转移到内存缓存，效率极大提高。

### 客户端优化

- 秒杀页面：静态化页面、缓存预热。秒杀前通过定时任务提前把商品的库存资源加载到缓存。
- **限制用户维度访问频率**：针对同一用户，做页面级别缓存，单元时间内请求，统一走缓存。
- 限制商品维度访问频率：大量请求同时间段查询同一个商品时，可以做页面级别缓存，不管下回是谁来访问，只要是这个页面就直接返回。
- SOA(面向服务架构)服务层优化：后端系统的控制可以通过消息队列、异步处理、提高并发等方式解决。对于超过系统水位线的请求，直接采取 「Fail-Fast」原则，拒绝掉。**降级，限流，熔断**。
- 秒杀链接加盐：URL通过加密算法做url，后台校验才能通过

### 秒杀整体流程图

![img](http://i2.51cto.com/images/blog/201803/11/bf7107f82e635020a43f12aa4a8dc856.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

**Lua脚本类似Redis事务，有一定的原子性，不会被其他命令插入，可以完成Redis的事务性才做。**

### 

## 基于redis的分布式锁实现

### 介绍

分布式环境下，基于本地单机的锁无法控制分布式系统中分开部署客户端的并发行为，此时**分布式锁**就应运而生了。关键是在分布式的应用服务器外，搭建一个存储服务器，存储锁信息，这时候我们很容易就想到了Redis。

- **SETEX key seconds value**

  将value关联到key，并将key生成时间设置为seconds

  这是一个原子性操作，关联值和生存时间会同一时间完成



### 可靠性

1. **互斥性。**在任意时刻，只有一个客户端能持有锁。
2. **不会发生死锁。**即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
3. **具有容错性。**只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。
4. **解铃还须系铃人。**加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。

### 注意点

- 这个锁必须要**设置一个过期时间**。
- 设置一个**随机字符串randomVal**是很有必要的，它保证了一个客户端**释放的锁必须是自己持有的那个锁**。
- 释放锁的操作必须使用Lua脚本来实现。释放锁其实包含三步操作：GET、判断和DEL，用Lua脚本来实现能保证这三步的原子性。

### 获取锁：

![img](https://upload-images.jianshu.io/upload_images/15137491-1560cfba95c076d9.png?imageMogr2/auto-orient/strip|imageView2/2/w/555/format/webp)

### 释放锁：

![img](https://upload-images.jianshu.io/upload_images/15137491-10a89d02d3ee6df9.png?imageMogr2/auto-orient/strip|imageView2/2/w/580/format/webp)

## redis跟数据库一致性

**比如更新数据库的同时为什么不马上更新缓存，而是删除缓存？**

考虑到更新数据库后更新缓存可能会因为多线程下导致写入脏数据（比如线程A先更新数据库成功，接下来要去更新缓存，接着线程B更新数据库，但B又更新了缓存，接着B的时间片用完了，线程A又更新了缓存）。

## AOP

面向切面编程:将**那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来**，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。

**动态地将代码切入到类的指定方法、指定位置上的编程思想就是面向切面的编程。**

### Spring AOP SpringBoot集成:

https://www.cnblogs.com/LemonFive/p/10983875.html

1、引入依赖

- 注意：在完成了引入AOP依赖包后，不需要去做其他配置。AOP的默认配置属性中，spring.aop.auto属性默认是开启的，也就是说只要引入了AOP依赖后，默认已经增加了@EnableAspectJAutoProxy，不需要在程序主类中增加@EnableAspectJAutoProxy来启用。

2、web请求入口：对应系统纵向的核心业务模块。

3、定义切面类：在类上添加@Aspect 和@Component 注解即可将一个类定义为切面类。

@Aspect 注解 使之成为切面类

@Component 注解 把切面类加入到IOC容器中

3、构造函数注解定义切入点

```
    /**
     * 定义切入点，切入点为com.example.demo.aop.AopController中的所有函数
     *通过@Pointcut注解声明频繁使用的切点表达式
     */
    @Pointcut("execution(public * com.example.demo.aop.AopController.*(..)))")
    public void BrokerAspect(){
 
    }
```

## 数据库分库分表

https://blog.csdn.net/azhuyangjun/article/details/86976514

关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。当数据量大的情况下性能下降严重。

数据库分布式核心内容无非就是数据切分（Sharding），以及切分后对数据的定位、整合。数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小。

## 为什么使用微服务架构，或者说优势是什么？

服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分成一组小的服务，每个服务运行独立的自己的进程中，服务之间互相协调、互相配合。**微服务架构最核心的环节**，主要是对服务的**横向拆分**。服务拆分就是讲一个完整的业务系统解耦为服务，**服务需要职责单一，之间没有耦合关系，能够独立开发和维护**。

由 SOA 架构 -> 微服务架构的转变

传统企业或者很多企业的软件，大多不止一套系统，都是各个独立大系统的堆砌。

- 扩展性差
- 可靠性不高
- 维护成本还很大
- 重复轮子很多

微服务架构，**将各个组件或者模块分散到各个服务中，对整个系统实现解耦。**将一个大系统，按照一定的业务，拆分成独立的组件。目的是为了分而治之，为了可重用。阿里巴巴提出 大中台，小前台。

- 微服务扩展性高
- 微服务可靠性高
- 微服务维护成本小
- 微服务几乎没有重复轮子
- 微服务业务隔离
- 微服务数据库解耦
- 自由（在某种程度上）选择实施技术/语言

服务化，强调 “化”！核心就是不同服务之间的通信。是一种以服务为中心的解决方案：

- 服务注册
- 服务发布
- 服务调用
- 服务监控
- 服务负载均衡

## 项目架构

https://blog.csdn.net/lyj2018gyq/article/details/84980103

![img](https://img-blog.csdnimg.cn/20181212215151153.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x5ajIwMThneXE=,size_16,color_FFFFFF,t_70)

**不管是来自于客户端（PC或移动端）的请求，还是服务内部调用。一切对服务的请求都会经过Zuul这个网关，然后再由网关来实现 鉴权、动态路由等等操作。Zuul就是我们服务的统一入口。**

## [B树和B+树的区别](https://www.cnblogs.com/20189223cjt/p/11262450.html)：

#### B+树的特征：

- 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），**每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。**
- **所有的叶子结点中包含了全部元素的信息**，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。**每一个叶子节点都带有指向下一个节点的指针，形成有序链表。**
- **所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素**。

#### B+树的优势：

- **单一节点存储更多的元素，使得查询的IO次数更少**。
- **所有查询都要查找到叶子节点，查询性能稳定**。
- **所有叶子节点形成有序链表，便于范围查询**。

### 范围查询的优势和区别：

**b树依靠的是中序遍历**

**b+树只需要在链表上做遍历就好了**

### 

