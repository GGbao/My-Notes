## [hashMap](https://zhuanlan.zhihu.com/p/21673805):

**线程不安全问题：**hashmap用数组+链表。数组是固定长度，链表太长就需要扩充数组长度进行rehash减少链表长度。如果两个线程同时触发扩容，在**移动节点时会导致一个链表中的2个节点相互引用，从而生成环链表**。jdk1.7及以前 **扩容时使用的头插法 并发时可能会形成环状链表造成死循环，1.8改为了尾插法** 可以避免这种问题 只是依然**避免不了节点丢失**的问题。

1.7下形成环以后去取值可能会发生同步修改异常，大部分情况取到null

1.8以后避免不了节点的丢失，取不到最后一位

**HashMap的初始容量是2的n次幂**，扩容也是2倍的形式进行扩容，是因为容量是2的n次幂，

1、n-1的二进制会全为1，位运算时可以充分散列。避免不必要的哈希冲突可以使得**添加的元素均匀分布**在HashMap中的数组上，**减少hash碰撞**，避免形成链表的结构，使得查询效率降低！

2、resize过程中不需要像JDK1.7的实现那样重新计算hash，只需要看**看原来的hash值新增的那个bit是1还是0**就好了，是**0的话索引没变(e.hash & oldCap) == 0**，是**1的话索引变成“原索引+oldCap”**

3、采用二进制位操作&，相对于%能够提高运算效率。根据反汇编：

&操作用了:3mov+1and+1sub  %操作用了：2mov+1cdp+1idiv	汇编代码即使数量一样，每条指令的执行速度也不一样。

前者只需5个CPU周期，而后者至少需要26个CPU周期

**求余运算**。需要先将10进制转成2进制到内存中进行计算，然后再把结果转换成10进制

**位运算**是直接在内存中进行，不需要经过这些转换

**但是位运算只能用于除数是2的n次方的数的求余**





## 什么是死锁？

### 一、定义

当线程互相持有对方所需要的资源时，会互相等待对方释放资源，如果线程都不主动释放所占有的资源，将产生死锁。

### 二、条件

1.互斥条件：进程对于所分配到的资源具有排它性，即一个资源只能被一个进程占用，直到被该进程释放  
2.请求和保持条件：一个进程因请求被占用资源而发生阻塞时，对已获得的资源保持不放。  
3.不剥夺条件：任何一个资源在没被该进程释放之前，任何其他进程都无法对他剥夺占用  
4.循环等待条件：当发生死锁时，所等待的进程必定会形成一个环路（类似于死循环），造成永久阻塞。

### 三、避免死锁

**1、最简单**的方法就是线程都是**以同样的顺序加锁和释放锁**，也就是破坏了第四个条件。

2、加锁时限，若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁。

3、死锁检测。

## 缓存雪崩

- 事后，redis持久化机制，RDB(快照)+AOF(追加文件)

1、redis高可用，搭建的集群，主从同步，读写分离。

2、错开缓存失效时间

3、本地缓存+Hystrix限流

4、数据预热：在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。

## 缓存击穿

1、接口层加入基础校验，简单参数校验不通过就返回

2、把找不到的key值也缓存到redis，并且设置较短的过期时间

3、nginx层设置对单个IP超出阈值都拉黑

4、布隆过滤器：利用简单高效的算法判断key是否存在于数据库

**将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。**

## 秒杀优化

https://blog.csdn.net/a724888/article/details/81038138

https://www.bilibili.com/read/cv5047955

### 架构设计思想

1、限流：控制大部分流量，只允许少部分流量进入服务器后端。

2、削峰：把瞬间的高流量变成平稳流量，利用缓存和消息中间件等技术。

3、异步处理：采用异步处理模块提高并发量，将同步的业务，设计成异步处理的任务，也是削峰的一种方式。

4、把部分数据和业务逻辑转移到内存缓存，效率极大提高。

### 客户端优化

- 秒杀页面：静态化页面、缓存预热。秒杀前通过定时任务提前把商品的库存资源加载到缓存。
- **限制用户维度访问频率**：针对同一用户，做页面级别缓存，单元时间内请求，统一走缓存。
- 限制商品维度访问频率：大量请求同时间段查询同一个商品时，可以做页面级别缓存，不管下回是谁来访问，只要是这个页面就直接返回。
- SOA(面向服务架构)服务层优化：后端系统的控制可以通过消息队列、异步处理、提高并发等方式解决。对于超过系统水位线的请求，直接采取 「Fail-Fast」原则，拒绝掉。**降级，限流，熔断**。
- 秒杀链接加盐：URL通过加密算法做url，后台校验才能通过

### 秒杀整体流程图

![img](http://i2.51cto.com/images/blog/201803/11/bf7107f82e635020a43f12aa4a8dc856.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

**Lua脚本类似Redis事务，有一定的原子性，不会被其他命令插入，可以完成Redis的事务性才做。**

### 

## 锁和CAS

https://blog.csdn.net/wen3011/article/details/78548521

### 锁

#### 悲观锁与乐观锁

独占锁是一种**悲观锁**，synchronized就是一种独占锁，会**导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁**。而另一个更加有效的锁就是乐观锁。所谓**乐观锁**就是，**每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止**。

#### 公平锁和非公平锁

https://www.bilibili.com/read/cv5333437

#### volatile

volatile变量是一和更轻量级的同步机制，因为在使用这些变量时**不会发生上下文切换和线程调度等操作**，但是volatile变量也存在一些局限：**不能用于构建原子的复合操作**，因此当一个变量依赖旧值时就不能使用volatile变量。

### CAS无锁算法

实现无锁的非阻塞算法有多种实现方法，其中 CAS（比较与交换，Compare and swap） 是一种有名的无锁算法。

CAS是一种 **乐观锁** 技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。



## 阻塞队列

| 方法\处理方式 | 抛出异常  | 返回特殊值 | 一直阻塞 | 超时退出           |
| :------------ | :-------- | :--------- | :------- | :----------------- |
| 插入方法      | add(e)    | offer(e)   | put(e)   | offer(e,time,unit) |
| 移除方法      | remove()  | poll()     | take()   | poll(time,unit)    |
| 检查方法      | element() | peek()     | 不可用   | 不可用             |

### 1、ArrayBlockingQueue

基于数组的阻塞队列实现，内部维护了一个定长数组，**内部还保存着两个整形变量**，分别标识着**队列的头部和尾部在数组中的位置**。生产者放入数据和消费者获取数据，都是**共用同一个锁对象**。数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，只会给代码带来额外的复杂性。而且在插入或删除元素时不会产生或销毁任何额外的对象实例。创建ArrayBlockingQueue时，我们还可以控制对象的内部锁是否采用公平锁，**默认采用非公平锁**。

### 2、LinkedBlockingQueue

基于链表的阻塞队列，内部维持着一个数据缓冲队列（该队列由链表构成），只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其**对于生产者端和消费者端分别采用了独立的锁来控制数据同步**，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。

如果没有指定其容量大小，LinkedBlockingQueue会**默认一个类似无限大小的容量**（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。

### 3、DelayQueue

DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue是一个没有大小限制的队列，因此往队列中**插入数据的操作（生产者）永远不会被阻塞**，而**只有获取数据的操作（消费者）才会被阻塞**。

　　使用场景：

　　DelayQueue使用场景较少，但都相当巧妙，常见的例子比如使用一个DelayQueue来**管理一个超时未响应的连接队列**。

### 4、PriorityBlockingQueue

基于优先级的阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），但需要注意的是PriorityBlockingQueue并**不会阻塞数据生产者**，而只会在没有可消费的数据时，**阻塞数据的消费者**。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现PriorityBlockingQueue时，**内部控制线程同步的锁采用的是公平锁**。

### 5、SynchronousQueue

SynchronousQueue，是一种无缓冲的等待队列，可以认为SynchronousQueue是一个**缓存值为1的阻塞队列**。有两种不同的方式，它们之间有着不太一样的行为。公平模式和非公平模式的区别:

　　如果采用**公平模式**：SynchronousQueue**会采用公平锁**，**并配合一个FIFO队列**来阻塞多余的生产者和消费者，从而体系整体的公平策略；

　　但如果是**非公平模式**（SynchronousQueue**默认**）：SynchronousQueue**采用非公平锁**，**同时配合一个LIFO队列**来管理多余的生产者和消费者，而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理。

## 非阻塞队列：

### ConcurrentLinkedQueue

 ConcurrentLinkedQueue是一个基于**单向链表的无界线程安全队列**，它采用**先进先出的规则对节点进行排序**，当我们添加一个元素的时候，它会添加到队列的尾部；当我们获取一个元素时，它会返回队列头部的元素。**入队和出队操作均利用CAS（compare and set）更新**，这样允许多个线程并发执行，并且不会因为加锁而阻塞线程，使得并发性能更好。





## 



## 基于redis的分布式锁实现

### 介绍

分布式环境下，基于本地单机的锁无法控制分布式系统中分开部署客户端的并发行为，此时**分布式锁**就应运而生了。关键是在分布式的应用服务器外，搭建一个存储服务器，存储锁信息，这时候我们很容易就想到了Redis。

- **SETEX key seconds value**

  将value关联到key，并将key生成时间设置为seconds

  这是一个原子性操作，关联值和生存时间会同一时间完成



### 可靠性

1. **互斥性。**在任意时刻，只有一个客户端能持有锁。
2. **不会发生死锁。**即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
3. **具有容错性。**只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。
4. **解铃还须系铃人。**加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。

### 注意点

- 这个锁必须要**设置一个过期时间**。
- 设置一个**随机字符串randomVal**是很有必要的，它保证了一个客户端**释放的锁必须是自己持有的那个锁**。
- 释放锁的操作必须使用Lua脚本来实现。释放锁其实包含三步操作：GET、判断和DEL，用Lua脚本来实现能保证这三步的原子性。

### 获取锁：

![img](https://upload-images.jianshu.io/upload_images/15137491-1560cfba95c076d9.png?imageMogr2/auto-orient/strip|imageView2/2/w/555/format/webp)

### 释放锁：

![img](https://upload-images.jianshu.io/upload_images/15137491-10a89d02d3ee6df9.png?imageMogr2/auto-orient/strip|imageView2/2/w/580/format/webp)

## redis跟数据库一致性

**比如更新数据库的同时为什么不马上更新缓存，而是删除缓存？**

考虑到更新数据库后更新缓存可能会因为多线程下导致写入脏数据（比如线程A先更新数据库成功，接下来要去更新缓存，接着线程B更新数据库，但B又更新了缓存，接着B的时间片用完了，线程A又更新了缓存）。

## AOP

面向切面编程:将**那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来**，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。

**动态地将代码切入到类的指定方法、指定位置上的编程思想就是面向切面的编程。**

### Spring AOP SpringBoot集成:

https://www.cnblogs.com/LemonFive/p/10983875.html

1、引入依赖

- 注意：在完成了引入AOP依赖包后，不需要去做其他配置。AOP的默认配置属性中，spring.aop.auto属性默认是开启的，也就是说只要引入了AOP依赖后，默认已经增加了@EnableAspectJAutoProxy，不需要在程序主类中增加@EnableAspectJAutoProxy来启用。

2、web请求入口：对应系统纵向的核心业务模块。

3、定义切面类：在类上添加@Aspect 和@Component 注解即可将一个类定义为切面类。

@Aspect 注解 使之成为切面类

@Component 注解 把切面类加入到IOC容器中

3、构造函数注解定义切入点

```
    /**
     * 定义切入点，切入点为com.example.demo.aop.AopController中的所有函数
     *通过@Pointcut注解声明频繁使用的切点表达式
     */
    @Pointcut("execution(public * com.example.demo.aop.AopController.*(..)))")
    public void BrokerAspect(){
 
    }
```

## 数据库分库分表

https://blog.csdn.net/azhuyangjun/article/details/86976514

关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。当数据量大的情况下性能下降严重。

数据库分布式核心内容无非就是数据切分（Sharding），以及切分后对数据的定位、整合。数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小。

## 为什么使用微服务架构，或者说优势是什么？

服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分成一组小的服务，每个服务运行独立的自己的进程中，服务之间互相协调、互相配合。**微服务架构最核心的环节**，主要是对服务的**横向拆分**。服务拆分就是讲一个完整的业务系统解耦为服务，**服务需要职责单一，之间没有耦合关系，能够独立开发和维护**。

由 SOA 架构 -> 微服务架构的转变

传统企业或者很多企业的软件，大多不止一套系统，都是各个独立大系统的堆砌。

- 扩展性差
- 可靠性不高
- 维护成本还很大
- 重复轮子很多

微服务架构，**将各个组件或者模块分散到各个服务中，对整个系统实现解耦。**将一个大系统，按照一定的业务，拆分成独立的组件。目的是为了分而治之，为了可重用。阿里巴巴提出 大中台，小前台。

- 微服务扩展性高
- 微服务可靠性高
- 微服务维护成本小
- 微服务几乎没有重复轮子
- 微服务业务隔离
- 微服务数据库解耦
- 自由（在某种程度上）选择实施技术/语言

服务化，强调 “化”！核心就是不同服务之间的通信。是一种以服务为中心的解决方案：

- 服务注册
- 服务发布
- 服务调用
- 服务监控
- 服务负载均衡

## 项目架构

https://blog.csdn.net/lyj2018gyq/article/details/84980103

![img](https://img-blog.csdnimg.cn/20181212215151153.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x5ajIwMThneXE=,size_16,color_FFFFFF,t_70)

**不管是来自于客户端（PC或移动端）的请求，还是服务内部调用。一切对服务的请求都会经过Zuul这个网关，然后再由网关来实现 鉴权、动态路由等等操作。Zuul就是我们服务的统一入口。**

## [B树和B+树的区别](https://www.cnblogs.com/20189223cjt/p/11262450.html)：

#### B+树的特征：

- 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），**每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。**
- **所有的叶子结点中包含了全部元素的信息**，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。**每一个叶子节点都带有指向下一个节点的指针，形成有序链表。**
- **所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素**。

#### B+树的优势：

- **单一节点存储更多的元素，使得查询的IO次数更少**。
- **所有查询都要查找到叶子节点，查询性能稳定**。
- **所有叶子节点形成有序链表，便于范围查询**。

### 范围查询的优势和区别：

**b树依靠的是中序遍历**

**b+树只需要在链表上做遍历就好了**

### 

